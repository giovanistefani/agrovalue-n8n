# Solu√ß√£o de Problemas - AgroValue N8N

Este guia ajuda a resolver problemas comuns no ambiente N8N local e na AWS.

## üê≥ Problemas com Docker Local

### Container N8N n√£o inicia

**Sintoma**: Container para logo ap√≥s iniciar
```bash
docker-compose -f docker/docker-compose.yml logs n8n
```

**Poss√≠veis Causas e Solu√ß√µes**:

1. **Porta j√° em uso**
   ```bash
   # Verificar processo usando a porta
   sudo lsof -i :5678
   # Parar processo
   sudo kill -9 <PID>
   ```

2. **Erro de permiss√£o**
   ```bash
   # Adicionar usu√°rio ao grupo docker
   sudo usermod -aG docker $USER
   # Fazer logout/login
   ```

3. **Vari√°veis de ambiente inv√°lidas**
   ```bash
   # Verificar arquivo .env.local
   cat configs/.env.local
   # Recriar se necess√°rio
   cp configs/.env.example configs/.env.local
   ```

### Erro de conex√£o com PostgreSQL

**Sintoma**: `ECONNREFUSED 172.20.0.3:5432`

**Solu√ß√£o**:
```bash
# Verificar status do PostgreSQL
docker-compose -f docker/docker-compose.yml ps postgres

# Reiniciar PostgreSQL
docker-compose -f docker/docker-compose.yml restart postgres

# Verificar logs
docker-compose -f docker/docker-compose.yml logs postgres

# Testar conex√£o manual
docker exec -it n8n_postgres psql -U n8n -d n8n -c "SELECT version();"
```

### Volume Docker n√£o monta

**Sintoma**: Dados n√£o persistem entre reinicializa√ß√µes

**Solu√ß√£o**:
```bash
# Verificar volumes
docker volume ls | grep n8n

# Recriar volumes se corrompidos
docker-compose -f docker/docker-compose.yml down -v
docker volume prune -f
./scripts/start-local.sh
```

### Erro de certificado SSL

**Sintoma**: Erro SSL no navegador (desenvolvimento local)

**Solu√ß√£o**:
```bash
# Regenerar certificado
rm -rf configs/nginx/ssl/*
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
    -keyout configs/nginx/ssl/key.pem \
    -out configs/nginx/ssl/cert.pem \
    -subj "/C=BR/ST=SP/L=Sao Paulo/O=AgroValue/CN=localhost"

# Reiniciar nginx
docker-compose -f docker/docker-compose.yml restart nginx
```

## ‚òÅÔ∏è Problemas com AWS

### Deploy Terraform falha

**Sintoma**: `Error: UnauthorizedOperation`

**Solu√ß√£o**:
```bash
# Verificar credenciais
aws sts get-caller-identity

# Verificar permiss√µes necess√°rias
aws iam get-user
aws iam list-attached-user-policies --user-name <seu-usuario>

# Configurar credenciais se necess√°rio
aws configure
```

### ECS Task n√£o inicia

**Sintoma**: Tasks ficam em estado `PENDING` ou `STOPPED`

**Diagn√≥stico**:
```bash
# Verificar eventos do servi√ßo
aws ecs describe-services \
    --cluster agrovalue-n8n-cluster \
    --services agrovalue-n8n-service \
    --query "services[0].events"

# Verificar logs da task
aws logs filter-log-events \
    --log-group-name /aws/ecs/agrovalue-n8n \
    --start-time $(date -d '1 hour ago' +%s)000
```

**Solu√ß√µes Comuns**:

1. **Erro de IAM**
   ```bash
   # Verificar role de execu√ß√£o
   aws iam get-role --role-name agrovalue-n8n-ecs-execution-role
   
   # Verificar pol√≠ticas anexadas
   aws iam list-attached-role-policies \
       --role-name agrovalue-n8n-ecs-execution-role
   ```

2. **Erro de Secrets Manager**
   ```bash
   # Verificar se secrets existem
   aws secretsmanager list-secrets \
       --query "SecretList[?contains(Name, 'agrovalue-n8n')]"
   
   # Verificar valores
   aws secretsmanager get-secret-value \
       --secret-id agrovalue-n8n/n8n-auth-password
   ```

3. **Recursos insuficientes**
   ```bash
   # Aumentar recursos temporariamente
   aws ecs update-service \
       --cluster agrovalue-n8n-cluster \
       --service agrovalue-n8n-service \
       --task-definition agrovalue-n8n-task \
       --desired-count 1
   ```

### RDS n√£o conecta

**Sintoma**: `connection refused` ou timeout

**Diagn√≥stico**:
```bash
# Verificar status RDS
aws rds describe-db-instances \
    --db-instance-identifier agrovalue-n8n-database \
    --query "DBInstances[0].DBInstanceStatus"

# Verificar security groups
aws ec2 describe-security-groups \
    --group-ids <sg-id> \
    --query "SecurityGroups[0].IpPermissions"
```

**Solu√ß√µes**:

1. **Security Group**
   ```bash
   # Verificar regras do SG
   aws ec2 describe-security-groups \
       --filters "Name=group-name,Values=*n8n-rds*"
   
   # Adicionar regra se necess√°rio (cuidado!)
   aws ec2 authorize-security-group-ingress \
       --group-id sg-xxx \
       --protocol tcp \
       --port 5432 \
       --source-group sg-yyy
   ```

2. **RDS parado**
   ```bash
   # Iniciar RDS
   aws rds start-db-instance \
       --db-instance-identifier agrovalue-n8n-database
   ```

### ALB retorna 502/503

**Sintoma**: Load balancer retorna erro de gateway

**Diagn√≥stico**:
```bash
# Verificar targets saud√°veis
aws elbv2 describe-target-health \
    --target-group-arn arn:aws:elasticloadbalancing:...

# Verificar health check
aws elbv2 describe-target-groups \
    --target-group-arns arn:aws:elasticloadbalancing:... \
    --query "TargetGroups[0].HealthCheckPath"
```

**Solu√ß√µes**:

1. **Health check falha**
   ```bash
   # Testar endpoint manualmente
   # Obter IP privado da task
   aws ecs describe-tasks \
       --cluster agrovalue-n8n-cluster \
       --tasks $(aws ecs list-tasks --cluster agrovalue-n8n-cluster --query "taskArns[0]" --output text)
   
   # Verificar se /healthz responde
   curl http://<task-private-ip>:5678/healthz
   ```

2. **Security group ECS**
   ```bash
   # Verificar se ALB pode acessar ECS
   aws ec2 describe-security-groups \
       --filters "Name=group-name,Values=*ecs-tasks*"
   ```

## üîß Ferramentas de Debug

### Script de Diagn√≥stico Completo

```bash
#!/bin/bash
# scripts/debug.sh

echo "üîç Diagn√≥stico AgroValue N8N"

# Verificar ambiente local
if [ -f "docker/docker-compose.yml" ]; then
    echo "üìã Status Docker Local:"
    docker-compose -f docker/docker-compose.yml ps
    
    echo "üìä Uso de recursos:"
    docker stats --no-stream
fi

# Verificar AWS
if command -v aws &> /dev/null; then
    echo "‚òÅÔ∏è  Status AWS:"
    
    # ECS
    aws ecs describe-clusters \
        --clusters agrovalue-n8n-cluster \
        --query "clusters[0].status" 2>/dev/null || echo "  Cluster n√£o encontrado"
    
    # RDS
    aws rds describe-db-instances \
        --db-instance-identifier agrovalue-n8n-database \
        --query "DBInstances[0].DBInstanceStatus" 2>/dev/null || echo "  RDS n√£o encontrado"
    
    # ALB
    aws elbv2 describe-load-balancers \
        --names agrovalue-n8n-alb \
        --query "LoadBalancers[0].State.Code" 2>/dev/null || echo "  ALB n√£o encontrado"
fi
```

### Logs Centralizados

```bash
# Todos os logs locais
docker-compose -f docker/docker-compose.yml logs --tail=100

# Logs AWS espec√≠ficos
aws logs filter-log-events \
    --log-group-name /aws/ecs/agrovalue-n8n \
    --start-time $(date -d '30 minutes ago' +%s)000 \
    --filter-pattern "ERROR"
```

### Health Check Manual

```bash
# Local
curl -f http://localhost:5678/healthz

# AWS (via ALB)
curl -f https://your-domain.com/healthz
# ou
curl -f http://your-alb-dns-name/healthz
```

## üìä Monitoramento Proativo

### Alertas CloudWatch

```bash
# Criar alerta para falhas de health check
aws cloudwatch put-metric-alarm \
    --alarm-name "N8N-HealthCheck-Failures" \
    --alarm-description "Alert on health check failures" \
    --metric-name UnHealthyHostCount \
    --namespace AWS/ApplicationELB \
    --statistic Average \
    --period 60 \
    --threshold 1 \
    --comparison-operator GreaterThanOrEqualToThreshold \
    --dimensions Name=TargetGroup,Value=your-target-group \
    --evaluation-periods 2
```

### Script de Monitoramento

```bash
#!/bin/bash
# scripts/monitor.sh

while true; do
    # Verificar health local
    if ! curl -sf http://localhost:5678/healthz > /dev/null 2>&1; then
        echo "‚ùå $(date): N8N local n√£o est√° respondendo"
    fi
    
    # Verificar health AWS
    if ! curl -sf http://your-alb-dns/healthz > /dev/null 2>&1; then
        echo "‚ùå $(date): N8N AWS n√£o est√° respondendo"
    fi
    
    sleep 30
done
```

## üÜò Recursos de Suporte

### Logs Detalhados

**Local**:
```bash
# Habilitar debug
echo "N8N_LOG_LEVEL=debug" >> configs/.env.local
docker-compose -f docker/docker-compose.yml restart n8n
```

**AWS**:
```bash
# Atualizar task definition para debug
aws ecs register-task-definition \
    --family agrovalue-n8n-task \
    --container-definitions '[{
        "name": "n8n",
        "environment": [
            {"name": "N8N_LOG_LEVEL", "value": "debug"}
        ]
    }]'
```

### Backup de Emerg√™ncia

```bash
# Backup r√°pido antes de mudan√ßas
./scripts/backup.sh --local-only --verify

# Backup AWS cr√≠tico
aws rds create-db-snapshot \
    --db-instance-identifier agrovalue-n8n-database \
    --db-snapshot-identifier emergency-backup-$(date +%Y%m%d-%H%M%S)
```

### Rollback R√°pido

```bash
# Voltar vers√£o anterior Docker
docker-compose -f docker/docker-compose.yml down
git checkout HEAD~1 -- docker/
docker-compose -f docker/docker-compose.yml up -d

# Rollback Terraform
cd terraform
terraform plan -destroy -target=aws_ecs_service.n8n
terraform apply -target=aws_ecs_service.n8n
```

## üìû Checklist de Emerg√™ncia

### Quando o N8N para de funcionar:

1. ‚úÖ Verificar logs: `docker-compose logs` ou CloudWatch
2. ‚úÖ Verificar recursos: CPU, mem√≥ria, disk
3. ‚úÖ Verificar conectividade: rede, database
4. ‚úÖ Verificar certificados: SSL, credenciais
5. ‚úÖ Verificar depend√™ncias: PostgreSQL, Redis
6. ‚úÖ Fazer backup: antes de mudan√ßas
7. ‚úÖ Aplicar fix: mudan√ßa m√≠nima necess√°ria
8. ‚úÖ Verificar health: endpoints funcionando
9. ‚úÖ Monitorar: por pelo menos 15 minutos
10. ‚úÖ Documentar: o que causou e como foi resolvido

### Contatos de Emerg√™ncia

- **AWS Support**: https://console.aws.amazon.com/support/
- **N8N Community**: https://community.n8n.io/
- **Docker Support**: https://docs.docker.com/
- **Terraform Issues**: https://github.com/hashicorp/terraform/issues

---

**üîß Dica**: Mantenha sempre um backup recente e teste os procedimentos de recovery regularmente.
